# SuperMega ML =)

## Have fun!
If you find this code useful, I will be glad if you use it in your GPL3-compatible licensed project.

**"Why GPL-3. Author, are you too proud?"**
> Nope. It's just that I'm fighting for free software, and any possibility that someone else is using my code on a project that people, myself included, will have to pay for is unacceptable.
> My code is neither perfect nor revolutionary. But the world is crazy, you know

Any help and criticism is greatly appreciated.

## Описание
Проект представляет собой мини-библиотеку Python3, предназначенную для решения задач прогнозирования, предсказания и выявления зависимостей методом линейной регрессии.
Система способна работать с достаточно большим количеством примеров (1000-100000), имеющих достаточно большое (100-1000) число признаков.

![preview](images/interface.png)

Также реализована функциональная программа с графическим интерфейсом.

### Общее представление
Задача линейной регрессии -- задача поиска, выявления произвольной зависимости некоторого показателя от набора признаков на множестве объектов. Это задача аппроксимации неизвестной зависимости некоторой известной гиперплоскостью.

Иными словами, мы можем построить, к примеру, такую прямую, которая максимально точно приблизится к зависимости стоимости квартиры от её площади, что также позволит предсказывать стоимость для тех квартир, для которых известна только прощадь.

Проект предоставляет не только библиотеку, как набор классов, предназначенных для произведения регрессионного анализа, но и графический интерфейс, опозволяющий настроить регрессию, обучить её и визуализировать результаты обучения регрессионной модели -- посмотреть на выявленную зависимость.

По сути, с помощью реализованного проекта можно производить анализ групп людей, строить гиперплоскости "тренда", и многое другое.

### Внешности
Функциональная программа с графическим интерфейсом PyQt5 предоставляет возможности конфигурирования регрессии, выбора метода оптимизации и изменения его параметров, выбора данных для анализа, обучения модели и просмотра результата.

![chose regression model options](images/TrainTab.png)
![train regression model](images/TrainTabAfterFit.png)

На картинках выше видно, как регерссионная модель приблизила красную плоскость к синим точкам примеров. В данном случае мы имеем дело с данными, в которых необходимо выявить зависимость одного значения (предикторного) от двух других (признаковых). Видно, что модель хорошо справилась с задачей.

Конкретный пример -- это зависимость количества посещений научно-популяных сообществ людьми от двух искуственных метрик.

### Внутренности
В общем и целом о внутреннем устройства проекта отлично расскажут _UML_-диаграммы.

Процесс взаимодействия пользователя с программой, реализующей возможности разработанной библиотеки, отображён на следующей диаграмме:

![user action with regression interface](images/ActionDuagram.png)

Внутренная логика (регрессия, оптимизация и яже с ними) представлена двумя модулями: _Frontend_ и _Backend_, внутри которых реализованы соответствующие классы:

![backend classes uml diagram](images/Backend.png)

![frontend classed uml diagram](images/Frontend.png)

![class interaction uml diagram](images/BackendAction.png)

#### Математика
В общем и целом алгоритм работы регрессионной модели достаточно прост и изящен: в начале процесса обучения модель только получает входной датасет с $M$ примерами, у каждого из которых $N$ признаков и одно предсказываемое значение. Далее создается случайный вектор $\vec{W}$ размера $N$. Затем в цикле некоторое количество раз выполняется следующая операция:

![\vec{W} = \vec{W}-\vec{Fix} * lr](images/formula1.png)

Где ![\vec{Fix}](images/formula2.png) -- поправочный вектор, а **lr** -- скорость обучения модели.

Поправочный вектор в данном случае вычисляется с помощью градиента одним из следующих методов:
  * Классический
  * Моменты
  * Стохастический-пакетный
  * Со случайной добавкой

Каждый из этих методов имеет некоторую оптимизацию классического градиента, призванную ускорить сходимость в процессе градиентного спуска.

Ниже приведён процесс вычисления классического градиента:

![\vec{Fix} = \nabla(Loss(\vec{W},X,\vec{y}))](images/formula3.png)

Где ![Loss(\vec{W},X,\vec{y})](images/formula4.png) -- функция ошибки в данной точке графика ошибки, **X** -- матрица признаков для некоторого пула примеров, ![\vec{y}](images/formula5.png) -- вектор ответов для соответствующих примеров матрицы примеров.

#### Код
С исходным кодом можно ознакомиться в [репозитории](https://github.com/pushsla/2020-plhl-graduation) проекта на GitHub.

## Зависимости
_Python3_
  * Модуль регрессионного анализа (_Backend_)
    1. _Numpy_
  * Модуль графического интерфейса (_Frontend_)
    1. _Numpy_
    1. _Pandas_
    2. _Matplitlib_
    3. _PyQt5_
